{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuprotsyk/bigdata-course/blob/main/notebooks/topic01_bigdata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa30c432",
      "metadata": {
        "id": "fa30c432"
      },
      "source": [
        "# Аналіз та обробка великих даних\n",
        "\n",
        "Ю.С. Процик. Курс лекцій"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af1f12bb",
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "af1f12bb"
      },
      "source": [
        "# Тема 1. Поняття великих даних. Екосистеми Hadoop та Spark\n",
        "\n",
        "### План\n",
        "\n",
        "1. [Еволюція даних](#1.-Еволюція-даних)\n",
        "2. [Що таке великі дані (Big Data)](#2.-Що-таке-великі-дані-(Big-Data))\n",
        "3. [Ключові характеристики великих даних та основні принципи роботи з ними](#3.-Ключові-характеристики-великих-даних-та-основні-принципи-роботи-з-ними)\n",
        "4. [Можливості застосування](#4.-Можливості-застосування)\n",
        "5. [Великі дані та Hadoop – аналогія з рестораном](#5.-Великі-дані-та-Hadoop-–-аналогія-з-рестораном)\n",
        "6. [Екосистема Hadoop](#6.-Екосистема-Hadoop)\n",
        "7. [Від Hadoop до Spark – Еволюція обробки даних](#7.-Від-Hadoop-до-Spark)\n",
        "8. [Вступ до Apache Spark та його архітектура](#8.-Вступ-до-Apache-Spark-та-його-архітектура)\n",
        "9. [Демо-приклад в Google Colab](#9.-Демо-приклад-в-Google-Colab)\n",
        "10. [Корисні ресурси](#10.-Корисні-ресурси)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c5763c3",
      "metadata": {
        "tags": [],
        "id": "9c5763c3"
      },
      "source": [
        "### 1. Еволюція даних\n",
        "\n",
        "Термін **\"Big Data\"** – Великі дані, використовується вже відносно давно, проте, навколо нього все ще багато плутанини щодо його значення та тлумачення. Справа в тому, що ця концепція постійно розвивається та переглядається, оскільки саме вона залишається рушійною силою багатьох хвиль цифрової трансформації, в тому числі штучного інтелекту, обробки інформації та алгоритмів пошуковиків та соціальних мереж.\n",
        "\n",
        "Якщо зібрати всю інформацію, яку людство накопичило з початку часів включно до 2000-го року, то виявиться, що її менше, ніж ми продукуємо зараз протягом лише однієї хвилини. Причинами різкого збільшення об'ємів даних є:\n",
        "- еволюція технологій\n",
        "- Іnternet of Things – IoT (Інтернет речей)\n",
        "- соціальні медіа\n",
        "- інші фактори\n",
        "\n",
        "Ми живемо у величезному цифровому просторі. Створюємо, ділимося, керуємо та зберігаємо всі аспекти нашого життя онлайн."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Еволюція технологій**\n",
        "\n",
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0101.png)\n",
        "\n",
        "На зміну стаціонарним телефонам прийшли смартфони, з'явилися хмарні сховища даних, самокеровані автомобілі.\n",
        "Дані з усіх наших пристроїв – комп'ютерів, планшетів та смартфонів постійно збираються та передаються в мережу.\n",
        "Та навіть з годинників, телевізорів, датчиків в розумних будинках, автомобілів, обладнань та з безлічі інших девайсів.\n"
      ],
      "metadata": {
        "id": "-lDrBVjnWNXR"
      },
      "id": "-lDrBVjnWNXR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Інтернет речей**\n",
        "\n",
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0102.png)\n",
        "\n",
        "> Термін Іnternet of Things – IoT, або Інтернет речей, відноситься до колективної мережі підключених пристроїв та технології, що полегшує зв'язок між пристроями та хмарою, а також між самими пристроями.\n",
        "\n",
        "IoT підключає фізичний пристрій до Інтернету та робить його розумнішим. Зараз у нас є розумні кондиціонери, телевізори тощо. Розумний кондиціонер постійно відстежує температуру в приміщенні разом із зовнішньою температурою і відповідно вирішує, якою має бути температура в кімнаті. А тепер уявіть, скільки даних буде згенеровано за рік розумним кондиціонером, встановленим у десятках і тисячах будинків."
      ],
      "metadata": {
        "id": "wLFIroYmWRtb"
      },
      "id": "wLFIroYmWRtb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Соціальні медіа**\n",
        "\n",
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0103.png)\n",
        "\n",
        "> Соціальні медіа (англ. Social media) – вид масмедіа, ряд онлайнових технологій на принципах Веб 2.0, завдяки яким споживачі контенту через свої дописи стають його співавторами і можуть взаємодіяти, співпрацювати, спілкуватися, ділитися інформацією або брати участь у будь-якій інший соціальній активності із теоретично усіма іншими користувачами певного сервісу.\n",
        "\n",
        "Ми самі продукуємо гігабайти інформації на сайтах соціальних мереж (вподобання, відео, фотографії, теги, коментарі тощо).\n"
      ],
      "metadata": {
        "id": "3uXptjGlWUaM"
      },
      "id": "3uXptjGlWUaM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Інші фактори**\n",
        "\n",
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0104.png)\n",
        "\n",
        "- Роздрібна торгівля\n",
        "- Банківська справа та фінанси\n",
        "- ЗМІ та розваги\n",
        "- Охорона здоров'я\n",
        "- Області освіти\n",
        "- Уряд\n",
        "- Транспорт, страхування тощо"
      ],
      "metadata": {
        "id": "8JjY1eozWXER"
      },
      "id": "8JjY1eozWXER"
    },
    {
      "cell_type": "markdown",
      "id": "8bc273d0",
      "metadata": {
        "id": "8bc273d0"
      },
      "source": [
        "### 2. Що таке великі дані (Big Data)\n",
        "\n",
        "Експоненціальне зростання даних створило нову сферу інтересів у галузі технологій та бізнесу під назвою **\"Big Data\"**. Загалом, набір даних або бізнес-проблема належать до Big Data, коли даних настільки багато або вони настільки складні, що їх стає неможливо зберігати, обробляти та аналізувати, використовуючи традиційні підходи до зберігання та аналізу даних.\n",
        "\n",
        "Скільки даних потрібно, щоб стати Big Data? Чи достатньо 100 терабайт або 1000 петабайт? Обсяг є лише одним із критеріїв, оскільки потреба в обробці даних у режимі реального часу або потреба в інтеграції структурованих і неструктурованих даних може кваліфікувати проблему як проблему великих даних.\n",
        "\n",
        "*Міжнародна корпорація даних (International Data Corporation, IDC) використовує 100 терабайт як розмір набору даних, який визначається як Big Data. Якщо дані потокові, розмір набору даних може бути меншим, ніж 100 терабайт, але все ще вважається Big Data до тих пір, поки дані, що створюються, збільшуються на понад 60% на рік.*\n",
        "\n",
        "> [Великі дані (англ. Big Data) в інформаційних технологіях](https://uk.wikipedia.org/w/index.php?title=%D0%92%D0%B5%D0%BB%D0%B8%D0%BA%D1%96_%D0%B4%D0%B0%D0%BD%D1%96) – набори інформації (як структурованої, так і неструктурованої) настільки великих розмірів, що традиційні способи та підходи (здебільшого засновані на рішеннях класу бізнесової аналітики та системах управління базами даних) не можуть бути застосовані до них. Альтернативне визначення називає великими даними **феноменальне прискорення нагромадження даних та їх ускладнення**. Важливо також відзначити те, що часто під цим поняттям у різних контекстах можуть мати на увазі **як дані великого об'єму, так і набір інструментів та методів** (наприклад, засоби масово-паралельної обробки даних системами категорії NoSQL, алгоритмами MapReduce, чи програмними каркасами проекту Hadoop)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Можна користуватись і більш простим визначенням:\n",
        "> **Великі дані** – це сукупність технологій, покликаних здійснювати три операції:\n",
        "> 1. Обробляти більші, у порівнянні зі «стандартними» сценаріями, об’єми даних.\n",
        "> 2. Уміти працювати з даними, що швидко надходять у дуже великих об’ємах. Тобто даних не просто багато, а їх постійно стає все більше й більше.\n",
        "> 3. Вміти працювати зі структурованими і мало структурованими даними паралельно і у різних аспектах.\n",
        "\n",
        "Вважається, що ці «вміння» дозволяють виявляти приховані закономірності, що вислизають від обмеженого людського сприйняття. Це дає безпрецедентні можливості оптимізації багатьох сфер нашого життя: державного управління, медицини, телекомунікацій, фінансів, транспорту, виробництва і так далі."
      ],
      "metadata": {
        "id": "hyFwqlYsWl2j"
      },
      "id": "hyFwqlYsWl2j"
    },
    {
      "cell_type": "markdown",
      "id": "e9555c6f",
      "metadata": {
        "id": "e9555c6f"
      },
      "source": [
        "### 3. Ключові характеристики великих даних та основні принципи роботи з ними\n",
        "\n",
        "Є п'ять ключових характеристик великих даних, які ще називають **\"п'ять V\"**\n",
        "\n",
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0105.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Volume (об'єм)**\n",
        "\n",
        "Накопичена база даних охоплює настільки великий обсяг інформації, що його практично нереально обробляти та зберігати традиційними способами. Для них потрібен зовсім новий підхід та вдосконалені інструменти.\n",
        "\n",
        "**2. Velocity (швидкість)**\n",
        "\n",
        "Швидкість накопичення та обробки даних, яка постійно збільшується. Останнім часом зростає попит на технології, що дозволяють використовувати обробку даних в режимі реального часу.\n",
        "\n",
        "**3. Variety (різноманітність)**\n",
        "\n",
        "Оскільки існує багато джерел, які створюють великі дані, типи даних, які вони генерують, відрізняються. Великі дані можуть бути *cтруктурованими* (таблиці), *напівструктурованими* (CSV, JSON, XML) або *неструктурованими* (відео, зображення, логи, аудіофайли). Раніше ми отримували дані з Excel і баз даних, тепер дані надходять у формі зображень, аудіо, відео, даних з датчиків тощо. Це різноманіття неструктурованих даних створює проблеми під час збору, зберігання, видобутку та аналізу даних.\n",
        "\n",
        "Дані, які мають належну структуру або ті, які можна легко зберегти у табличній формі в будь-яких реляційних базах даних, таких як Oracle, SQL Server або MySQL, відомі як *структуровані дані*.\n",
        "\n",
        "*Напівструктуровані дані* – це дані, які не повністю відформатовані, але їх можна відносно легко обробляти, оскільки вони містять теги або значення, розділені комами, тощо.\n",
        "\n",
        "*Неструктуровані дані* – це дані, які не мають жодної структури. Вони можуть бути у будь-якій формі, не існує заздалегідь визначеної моделі даних."
      ],
      "metadata": {
        "id": "4SVNQMljW0b9"
      },
      "id": "4SVNQMljW0b9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**4. Value (цінність)**\n",
        "\n",
        "Ця характеристика пікреслює економічну доцільність обробки великих об’ємів даних у відповідних умовах. Добре мати доступ до великих даних, але якщо неможливо перетворити їх на цінну інформацію, вони марні. Тобто потрібно враховувати, які переваги отримує організація, що працює з великими даними.\n",
        "\n",
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0106.png)"
      ],
      "metadata": {
        "id": "PbkZVelcW25r"
      },
      "id": "PbkZVelcW25r"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Veracity (достовірність)**\n",
        "\n",
        "Маючи справу з великими даними, організації повинні враховувати їх достовірність. Наприклад, люди можуть створювати обліковий запис та використовувати неправдиву контактну інформацію. Якість зафіксованих даних може сильно відрізнятися, тим самим впливаючи на точний аналіз.\n",
        "\n",
        "На зображенні нижче в таблиці бракує кількох значень. Крім того, очевидно, що мінімальне значення в 3-му рядку (15000) не є достовірним. Те саме стосується стандартного відхилення в рядку 2.\n",
        "\n",
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0107.png)"
      ],
      "metadata": {
        "id": "D68yR77aW7hD"
      },
      "id": "D68yR77aW7hD"
    },
    {
      "cell_type": "markdown",
      "id": "77dd726b",
      "metadata": {
        "id": "77dd726b"
      },
      "source": [
        "\n",
        "Основні принципи роботи з великими даними такі:\n",
        "\n",
        "- **Горизонтальна масштабованість.** Це – базовий принцип обробки великих даних. Як вже було зазначено, великих даних з кожним днем стає все більше. Відповідно, необхідно збільшувати кількість обчислювальних вузлів, за якими розподіляються ці дані, при чому обробка має відбуватись без погіршення продуктивності.\n",
        "- **Відмовостійкість.** Цей принцип витікає з попереднього. Оскільки обчислювальних вузлів у кластері може бути багато (іноді десятки тисяч) та їх кількість, не виключено, буде збільшуватись, зростає ймовірність виходу машин з ладу. Методи роботи з великими даними мають враховувати ймовірність таких ситуацій і передбачати превентивні заходи.\n",
        "- **Локальність даних.** Оскільки дані розподілені по великій кількості обчислювальних вузлів, то, якщо вони фізично знаходяться на одному сервері, а обробляються на іншому, витрати на передачу даних можуть бути невиправдано великими. Тому обробку даних бажано проводити на тій же машині, на якій вони зберігаються.\n",
        "\n",
        "Ці принципи відрізняються від тих, які характерні для традиційних, централізованих, вертикальних моделей зберігання добре структурованих даних. Власне, для роботи з великими даними розробляються підходи і технології."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "507df2c1",
      "metadata": {
        "id": "507df2c1"
      },
      "source": [
        "### 4. Можливості застосування\n",
        "\n",
        "Майже всі галузі сьогодні так чи інакше використовують програми Big Data\n",
        "\n",
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0108.png)\n",
        "\n",
        "\n",
        "- **Охорона здоров'я**. Використовуючи петабайти даних пацієнтів, організація може отримувати значущу інформацію, а потім створювати програми, які здатні заздалегідь передбачити погіршення стану пацієнта.\n",
        "\n",
        "\n",
        "- **Телекомунікації**. Сектори телекомунікацій збирають інформацію, аналізують її та пропонують рішення для різних проблем. Використовуючи програми Big Data, телекомунікаційні компанії змогли значно зменшити втрату пакетів даних, яка виникає, коли мережі перевантажені, і, таким чином, забезпечити безперебійне з’єднання для своїх клієнтів.\n",
        "\n",
        "\n",
        "- **Роздрібна торгівля**. Роздрібна торгівля має найнижчу маржу та є одним із найбільших бенефіціарів великих даних. Метою використання великих даних у роздрібній торгівлі є бажання якомога краще зрозуміти поведінку споживачів. Механізм рекомендацій Amazon надає пропозиції на основі історії веб-перегляду споживача.\n",
        "\n",
        "\n",
        "- **Контроль дорожнього руху**. Затори на дорогах є серйозною проблемою для багатьох міст у всьому світі. Ефективне використання даних і датчиків є ключем до кращого управління трафіком, оскільки міста стають дедалі густонаселенішими.\n",
        "\n",
        "\n",
        "- **Виробництво**. Аналіз великих даних у обробній промисловості може зменшити кількість дефектів компонентів, покращити якість продукції, підвищити ефективність і заощадити час і гроші.\n",
        "\n",
        "\n",
        "- **Якість пошуку**. Кожного разу, коли ми отримуємо інформацію з Google, ми одночасно генеруємо дані для неї. Google зберігає ці дані та використовує їх для покращення якості пошуку."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89a25960",
      "metadata": {
        "id": "89a25960"
      },
      "source": [
        "### 5. Великі дані та Hadoop – аналогія з рестораном\n",
        "\n",
        "Потужним інструментом для роботи з великими даними є фреймворк **Hadoop** від Apache foundation.\n",
        "\n",
        "Щоб зрозуміти проблеми, пов’язані з великими даними, і те, як їх вирішує Hadoop, проведемо аналогію з роботою ресторану.\n",
        "\n",
        "Боб – бізнесмен, який відкрив невеликий ресторан. Спочатку у своєму ресторані він отримував два замовлення на годину, і в його ресторані був один шеф-кухар з однією полицею, якої було достатньо, щоб обробити всі замовлення.\n",
        "\n",
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0109-hadoop.png)\n",
        "<center>Традиційний сценарій</center>\n",
        "\n",
        "Давайте порівняємо приклад ресторану з традиційним сценарієм, коли дані генеруються зі стабільною швидкістю, а системи, такі як RDBMS (Реляційні системи керування базами даних), здатні впоратися з ними, як шеф-кухар Боба. Тут ви можете пов’язати сховище даних із харчовою полицею в ресторані та традиційний блок обробки з шеф-кухарем, як показано на рисунку вище.\n",
        "\n",
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0110-hadoop.png)\n",
        "<center>Традиційний сценарій</center>\n",
        "\n",
        "Через кілька місяців Боб вирішив розширити свій бізнес і тому почав приймати онлайн-замовлення та додав у меню ресторану ще кілька страв, щоб залучити більшу аудиторію. В результаті швидкість, з якою вони отримували замовлення, зросла до тривожної цифри в 10 замовлень на годину, і одному кухарю стало досить важко з ними справлятися. Усвідомлюючи складність ситуації, Боб почав думати про вихід.\n",
        "\n",
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0111-hadoop.png)\n",
        "<center>Сценарій розподіленої обробки</center>\n",
        "\n",
        "Подібним чином у сценарії великих даних дані почали генеруватися із загрозливою швидкістю з появою соціальних мереж, смартфонів тощо.\n",
        "\n",
        "Тепер традиційна система, як і кухар у ресторані Боба, була недостатньо ефективною, щоб впоратися з цими раптовими змінами. Виникла потреба в стратегії іншого роду вирішення цієї проблеми.\n",
        "\n",
        "Після довгих досліджень Боб знайшов рішення: найняв ще 4 шеф-кухарів, щоб впоратися з величезною кількістю отриманих замовлень. Все йшло досить добре, але це рішення призвело до ще однієї проблеми. Оскільки всі кухарі ділили одну полицю з продуктами, сама полиця з їжею ставала вузьким місцем усього процесу. Отже, рішення було не таким ефективним, як вважав Боб.\n",
        "\n",
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0112-hadoop.png)\n",
        "<center>Помилковий сценарій розподіленої обробки</center>\n",
        "\n",
        "Подібним чином, щоб вирішити проблему обробки величезних наборів даних, було встановлено декілька блоків паралельної обробки даних (подібно до того, як Боб найняв 4 кухарів). Але навіть у цьому випадку використання кількох процесорів не було ефективним рішенням, оскільки централізований блок зберігання став вузьким місцем.\n",
        "\n",
        "Іншими словами, продуктивність усієї системи залежить від продуктивності центрального накопичувача. Тому, коли наше центральне сховище виходить з ладу, вся система опиняється під загрозу.\n",
        "\n",
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0113-hadoop.png)\n",
        "<center>Вирішення проблеми ресторану</center>\n",
        "\n",
        "Боб запропонував інше ефективне рішення: він розділив усіх шеф-кухарів на дві ієрархії, тобто молодшого та головного шеф-кухаря, і виділив кожному молодшому шеф-кухарю полицю для їжі. Припустимо, що готується м’ясна підлива. Тепер, за планом Боба, один молодший шеф-кухар буде готувати м'ясо, а інший молодший шеф-кухар – соус. Далі вони передадуть м’ясо та соус шеф-кухарю, де той приготує м’ясний соус після поєднання обох інгредієнтів, який потім буде доставлено як кінцеве замовлення.\n",
        "\n",
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0114-hadoop.png)\n",
        "<center>Hadoop та аналогія з рестораном</center>\n",
        "\n",
        "Hadoop працює подібно до ресторану Боба."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d9bd3ce",
      "metadata": {
        "id": "2d9bd3ce"
      },
      "source": [
        "### 6. Екосистема Hadoop\n",
        "\n",
        "**Apache Hadoop** – вільна програмна платформа і фреймворк для організації розподіленого зберігання і обробки наборів великих даних з використанням моделі програмування MapReduce, при якій завдання ділиться на багато дрібніших відособлених фрагментів, кожен з яких може бути запущений на окремому вузлі кластера, що складається з серійних комп'ютерів. Всі модулі в Hadoop спроєктовані з врахуванням припущення, що апаратне забезпечення часто виходить з ладу і такі ситуації повинні автоматично опрацьовуватись фреймворком.\n",
        "\n",
        "Спочатку Hadoop був, в першу чергу, інструментом для зберігання даних і запуску MapReduce-задач, проте зараз Hadoop являє собою великий стек технологій, так чи інакше пов'язаних з обробкою великих даних (не лише за допомогою MapReduce).\n",
        "\n",
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0115-hadoop.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Основними (core) компонентами Hadoop є:\n",
        "\n",
        "- **Hadoop Common** – набір бібліотек програмних модулів, скриптів та утиліт, які призначені для створення програмної інфраструктури, що лежить в основі роботи всіх інших компонентів і продуктів.\n",
        "\n",
        "- **Hadoop Distributed File System (HDFS)** – розподілена файлова система, що дозволяє зберігати інформацію практично необмеженого обсягу.\n",
        "\n",
        "- **Hadoop YARN** – фреймворк для управління ресурсами кластера та менеджменту задач (включає фреймворк MapReduce)."
      ],
      "metadata": {
        "id": "gzWoy0Q3XOYu"
      },
      "id": "gzWoy0Q3XOYu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Також існує велика кількість проектів, що безпосередньо пов'язані з Hadoop, але не входять до Hadoop core:\n",
        "\n",
        "- **Hive** – інструмент побудови SQL-подібних запитів для роботи з великими даними (перетворює SQL-запити на серію MapReduce–задач);\n",
        "\n",
        "- **Pig** – мова програмування високого рівня для аналізу даних. Один рядок коду цією мовою може перетворитися на послідовність MapReduce-задач;\n",
        "\n",
        "- **Hbase** – колонкова (стовпчикова) база даних, що реалізує парадигму BigTable;\n",
        "\n",
        "- **Cassandra** – високопродуктивна розподілена база даних «Ключ-значення»;\n",
        "\n",
        "- **ZooKeeper** – сервіс для розподіленого зберігання конфігурації та синхронізації змін цієї конфігурації;\n",
        "\n",
        "- **Mahout** – бібліотека і рушій машинного навчання на великих даних.\n",
        "\n",
        "Окремо слід відзначити проект **Apache Spark**, який є рушієм для розподіленої обробки даних. Не зважаючи на те, що Apache Spark зазвичай використовує для своєї роботи компоненти Hadoop, такі як HDFS і YARN, останнім часом він став популярнішим за нього. На те є вагомі причини, які ми з'ясуємо згодом."
      ],
      "metadata": {
        "id": "5qpCbhS8XRag"
      },
      "id": "5qpCbhS8XRag"
    },
    {
      "cell_type": "markdown",
      "id": "fcdb2e0a",
      "metadata": {
        "id": "fcdb2e0a"
      },
      "source": [
        "Раніше встановлення Hadoop було досить важким завданням – потрібно було окремо конфігурувати кожну машину в кластері, стежити за тим, щоб нічого не забути, акуратно налаштовувати моніторинги. Зі зростанням популярності Hadoop з'явилися компанії, які почали надавали власні дистрибутиви Hadoop та інструменти для спрощеного керування кластером. Наприклад, Cloudera (об'єдналася з Hortonworks у 2019 році) пропонує Cloudera Data Platform (CDP).\n",
        "\n",
        "Щоб просто \"спробувати\" Hadoop, немає потреби у дорогому серверному обладнанні. Можна скористатися Cloudera Data Platform (CDP) Trial або розгорнути Hadoop у локальному середовищі за допомогою контейнерів чи віртуальних машин."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12981479",
      "metadata": {
        "id": "12981479"
      },
      "source": [
        "Давайте розберемося, як саме Hadoop забезпечує вирішення основних проблем великих даних.\n",
        "\n",
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0116.png)\n",
        "\n",
        "**Проблема**: Зберігання величезних об'ємів даних, що експоненціально зростають\n",
        "\n",
        "**Рішення**: HDFS\n",
        "\n",
        "HDFS не замінює файлову систему Linux на окремих серверах, а розташовується поверх кластеру серверів як єдина файлова система, що охоплює весь кластер.\n",
        "\n",
        "HDFS забезпечує розподілений спосіб зберігання даних. Розділяє файли на блоки (типовий розмір блоку – 128 МБ) та зберігає їх у кластері (якщо це можливо, кожен блок розміщуватиметься на іншому вузлі даних – DataNode). Крім того, під час зберігання блоки даних реплікуються на різних DataNodes для **забезпечення відмовостійкості**.\n",
        "\n",
        "Hadoop використовує **горизонтальне масштабування** замість вертикального. При горизонтальному масштабуванні можна додавати нові вузли до кластера HDFS під час роботи відповідно до вимог, замість того, щоб збільшувати апаратний стек, наявний у кожному вузлі."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee4523f4",
      "metadata": {
        "id": "ee4523f4"
      },
      "source": [
        "**Проблема**: Зберігання різнорідних даних\n",
        "\n",
        "**Рішення**: HDFS\n",
        "\n",
        "У HDFS можна зберігати всі типи даних, незалежно від того, є вони структурованими, напівструктурованими чи неструктурованими. У HDFS немає попередньої перевірки схеми."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b2e99fc",
      "metadata": {
        "id": "2b2e99fc"
      },
      "source": [
        "**Проблема**: Швидкий доступ та обробка даних\n",
        "\n",
        "**Рішення**: MapReduce\n",
        "\n",
        "- Паралельна обробка даних, наявних у HDFS\n",
        "- Дані обробляються локально, тобто кожен вузол відповідає за обробку даних, які на ньому зберігаються (**код надсилається до даних**, а не навпаки)\n",
        "\n",
        "Замість переміщення даних з різних вузлів до одного головного вузла для обробки, логіка обробки надсилається до вузлів, де зберігаються дані, щоб кожен вузол міг обробляти частину даних паралельно. Нарешті, всі проміжні результати, створені кожним вузлом, об’єднуються разом, а остаточний результат надсилається назад клієнту."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Від Hadoop до Spark – Еволюція обробки даних\n",
        "\n",
        "Ми щойно розібрали Hadoop MapReduce. Він зробив революцію, дозволивши обробляти петабайти даних. Але уявіть, що ви пишете складний алгоритм, де дані мають пройти через 10 кроків. У MapReduce після кожного кроку система змушена записати результат на диск, а потім знову його прочитати. Це як готувати страву, де після кожного нарізаного овоча ви миєте дошку, ховаєте ніж у шафу, а потім знову все дістаєте. Це повільно. Саме цю проблему вирішив Spark."
      ],
      "metadata": {
        "id": "ocpvK5ioMGgF"
      },
      "id": "ocpvK5ioMGgF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Чому Spark замінив MapReduce?\n",
        "\n",
        "- **In-memory computing:** Основна проблема класичного MapReduce – постійний запис проміжних результатів на диск. Spark тримає дані в оперативній пам’яті, поки це можливо.\n",
        "\n",
        "- **Швидкість:** Це дає колосальний приріст – до 100 разів швидше в пам'яті та до 10 разів навіть при роботі з диском.\n",
        "\n",
        "- **Універсальність:** Підтримка Batch (пакетної) обробки, Streaming (потокової), Machine Learning та Graph обробки в одному фреймворку.\n",
        "\n",
        "- **Легкість написання коду**: Spark пропонує лаконічний API на Python (PySpark), Scala, Java та R."
      ],
      "metadata": {
        "id": "33O_scWPMhSh"
      },
      "id": "33O_scWPMhSh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Фундамент Spark: Концепція RDD\n",
        "\n",
        "В основі Spark лежить концепція **RDD (Resilient Distributed Datasets)** – відмовостійких розподілених наборів даних.\n",
        "\n",
        "- **Resilient (Відмовостійкий)**: Якщо частина даних втрачена через збій вузла, Spark знає, як їх відновити, використовуючи механізм Lineage (граф походження даних).\n",
        "\n",
        "- **Distributed (Розподілений)**: Дані розбиті на частини (партиції) і зберігаються на різних вузлах кластера.\n",
        "\n",
        "- **Lazy Evaluation (Ліниві обчислення)**: Spark не виконує операції миттєво. Він будує план (DAG – Directed Acyclic Graph) і запускає його лише тоді, коли потрібно отримати кінцевий результат (наприклад, зберегти файл або вивести на екран)."
      ],
      "metadata": {
        "id": "xMzIWLw4Ng6S"
      },
      "id": "xMzIWLw4Ng6S"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Вступ до Apache Spark та його архітектура\n",
        "\n",
        "#### Контекст та еволюція"
      ],
      "metadata": {
        "id": "p7FBi0PD7I_A"
      },
      "id": "p7FBi0PD7I_A"
    },
    {
      "cell_type": "markdown",
      "id": "9af23ad1-3216-44de-b57c-3af46b201fd3",
      "metadata": {
        "id": "9af23ad1-3216-44de-b57c-3af46b201fd3"
      },
      "source": [
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0117-databricks.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Почнемо з того, звідки взявся Spark. Усе почалося у 2009 році в лабораторії AMPLab Каліфорнійського університету в Берклі (UC Berkeley's AMPLab). На відміну від Hadoop, який фокусувався на дискових обчисленнях, розробники Spark шукали спосіб прискорити роботу в пам'яті. Важливі віхи: у 2013 проєкт передали Apache Foundation, а у 2014 він став топовим проєктом Apache. Сьогодні розвитком Spark керує компанія Databricks, постійно додаючи нові можливості, такі як Delta Lake (2018) та Unity Catalog (2021)."
      ],
      "metadata": {
        "id": "E0udJuLhUddG"
      },
      "id": "E0udJuLhUddG"
    },
    {
      "cell_type": "markdown",
      "id": "483df99d-58f8-4284-8aa7-6351be2128c2",
      "metadata": {
        "id": "483df99d-58f8-4284-8aa7-6351be2128c2"
      },
      "source": [
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0118-databricks.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dba70356-32d3-450c-a773-c21ea12432cd",
      "metadata": {
        "id": "dba70356-32d3-450c-a773-c21ea12432cd"
      },
      "source": [
        "Spark – це не просто одна бібліотека, а ціла екосистема.\n",
        "\n",
        "**Spark Core Engine** (ядро Spark) забезпечує фундамент для всієї екосистеми. Воно відповідає за критичні системні функції: керування пам’яттю, планування завдань, розподіл обчислень та автоматичне відновлення після збоїв.\n",
        "\n",
        "Взаємодія з ядром відбувається через різні рівні програмних інтерфейсів:\n",
        "\n",
        "- Низькорівневий **RDD API** – забезпечує повний контроль над даними у пам'яті.\n",
        "\n",
        "- Високорівневі API (**DataFrame API** та **SQL API**) – пропонують зручну роботу зі структурованими даними та автоматичну оптимізацію коду.\n",
        "\n",
        "Ці інструменти доступні для багатьох мов програмування, зокрема Python, Scala та Java, які мають повну підтримку обох рівнів API. Мова R також підтримується, проте вона зорієнтована переважно на роботу з високорівневими DataFrame.\n",
        "\n",
        "Спеціалізовані бібліотеки, побудовані поверх основного ядра, такі як **Spark SQL**, **MLlib**, **GraphX** та **Structured Streaming**, надають розширені функціональні можливості для різноманітних сценаріїв використання:\n",
        "\n",
        "- **Spark SQL**: Робота зі структурованими даними та підтримка запитів SQL.\n",
        "\n",
        "- **MLlib**: Масштабована бібліотека для машинного навчання.\n",
        "\n",
        "- **GraphX**: API для обробки графів та паралельних обчислень у них.\n",
        "\n",
        "- **Structured Streaming**: Обробка потокових даних у реальному часі."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Архітектура та ролі"
      ],
      "metadata": {
        "id": "umL0ZgIv97xw"
      },
      "id": "umL0ZgIv97xw"
    },
    {
      "cell_type": "markdown",
      "id": "83c82971-492f-4162-bfa5-357359bf896c",
      "metadata": {
        "id": "83c82971-492f-4162-bfa5-357359bf896c"
      },
      "source": [
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0119-databricks.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cdfe762-ba29-4966-8cd6-cb465b4f2b99",
      "metadata": {
        "id": "4cdfe762-ba29-4966-8cd6-cb465b4f2b99"
      },
      "source": [
        "Spark використовує архітектуру Master-Slave.\n",
        "\n",
        "**Драйвер (Driver)** є центральним компонентом, який керує життєвим циклом програми та виконанням. Він спілкується з **Cluster Manager** (YARN, K8s або Standalone), щоб отримати ресурси.\n",
        "\n",
        "**Менеджер кластера (Master)** виділяє ресурси та призначає завдання робочим вузлам (воркерам).\n",
        "\n",
        "**Воркери (Workers)** виконують завдання, призначені драйвером, запускають код і повертають результати.\n",
        "\n",
        "**Виконавці (Executors)** працюють на робочих вузлах, забезпечуючи безпосереднє виконання завдань та кешування даних."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0120-databricks.png)"
      ],
      "metadata": {
        "id": "WThGAARGF2jT"
      },
      "id": "WThGAARGF2jT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eask71TnF2jq"
      },
      "source": [
        "З погляду коду, все починається зі `SparkSession`. Введений у версії 2.0, він замінив старі розрізнені контексти. Це ваша \"вхідна точка\". Якщо ви працюєте в Databricks, об'єкт `spark` вже створений для вас автоматично. В іншому середовищі ви створюєте його через `builder`, як показано на прикладі коду.\n",
        "\n",
        "До версії Spark 2.0 архітектура була дещо роздробленою. Ось як змінилася структура взаємодії:\n",
        "\n",
        "- **SparkContext**: Використовувався для доступу до низькорівневих API (RDD).\n",
        "\n",
        "- **SQLContext/HiveContext**: Використовувалися для роботи зі структурованими даними та SQL.\n",
        "\n",
        "- **SparkSession (Сьогодні)**: Об'єднує все вищезгадане. Це робить код чистішим, оскільки вам більше не потрібно ініціалізувати кілька об'єктів для різних завдань."
      ],
      "id": "eask71TnF2jq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0121-databricks.png)"
      ],
      "metadata": {
        "id": "rNm6ihtlNtf8"
      },
      "id": "rNm6ihtlNtf8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d528e5b0-5a2e-40b4-919c-7e13e8e5519b"
      },
      "source": [
        "**Драйвер** – це диригент. Він створює `SparkSession` для зв'язку з кластером, аналізує ваш код і перетворює його на логічний план, будуючи **орієнтований (спрямований) ациклічний граф (Directed Acyclic Graph, DAG)** для обробки даних. Його робота – розрізати цей план на дрібні завдання (Tasks), розіслати їх Виконавцям (Executors) і чекати на результат, щоб повернути його вам (Клієнту)."
      ],
      "id": "d528e5b0-5a2e-40b4-919c-7e13e8e5519b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0122-databricks.png)"
      ],
      "metadata": {
        "id": "u9WHwhV_PRxC"
      },
      "id": "u9WHwhV_PRxC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Виконавці (Executors)** працюють на робочих вузлах, причому кожен вузол здатний приймати кілька Виконавців одночасно. Керування ресурсами налаштовується через параметри `spark.executor.cores` та `spark.executor.memory`.\n",
        "\n",
        "Виконавці можуть зберігати результати в енергонезалежному сховищі, а також звітувати Драйверу про статус виконання призначених завдань."
      ],
      "metadata": {
        "id": "sY5hYCW5PZx5"
      },
      "id": "sY5hYCW5PZx5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Логіка виконання"
      ],
      "metadata": {
        "id": "l1CZdpsgGjtE"
      },
      "id": "l1CZdpsgGjtE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0123-databricks.png)"
      ],
      "metadata": {
        "id": "8jKZIdG2P_V8"
      },
      "id": "8jKZIdG2P_V8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://raw.githubusercontent.com/yuprotsyk/bigdata-course/refs/heads/main/img/img0124-databricks.png)"
      ],
      "metadata": {
        "id": "EFPl4W5dQZyq"
      },
      "id": "EFPl4W5dQZyq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Коли ви запускаєте обчислення, Spark будує **орієнтований ациклічний граф (DAG)**.\n",
        "\n",
        "- **Орієнтований потоку:** Операції рухаються послідовно від одного етапу до наступного, без зворотних циклів.\n",
        "\n",
        "- **Ациклічна структура:** Така побудова (DAG) гарантує успішне завершення обчислень, унеможливлюючи виникнення нескінченних циклів.\n",
        "\n",
        "План розбивається на **Stages (Етапи)** – це групи завдань (Tasks), які можуть виконуватися паралельно.\n"
      ],
      "metadata": {
        "id": "TV86yF0WQZJP"
      },
      "id": "TV86yF0WQZJP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "І нарешті, ієрархія того, як Spark бачить вашу роботу.\n",
        "\n",
        "1. **Application** – це вся ваша сесія.\n",
        "\n",
        "2. **Jobs (Роботи)** – це операції високого рівня, які запускаються діями (actions), як-от `.collect()` або `.save()`.\n",
        "\n",
        "3. **Stages (Етапи)** – розділяють кожну роботу на менші незалежні блоки, які можуть виконуватися паралельно (розділення зазвичай відбувається в точках перемішування даних – shuffle).\n",
        "\n",
        "4. **Tasks (Завдання)** – найменші одиниці роботи, які безпосередньо виконуються Виконавцями (Executors).\n",
        "\n",
        "**Паралельне виконання:** У межах одного етапу завдання виконуються незалежно одне від одного, використовуючи архітектуру **\"Shared Nothing\"** (відсутність спільних ресурсів), що дозволяє легко масштабувати обчислення."
      ],
      "metadata": {
        "id": "jN_YF8ehQY3o"
      },
      "id": "jN_YF8ehQY3o"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Демо-приклад в Google Colab\n",
        "\n",
        "Подивимося, як запустити Spark у Google Colab і як наші знання про Driver, Executors та про згаданий на початку RDD втілюються в життя."
      ],
      "metadata": {
        "id": "4BbMSM3dg-YV"
      },
      "id": "4BbMSM3dg-YV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Підготовка та ініціалізація\n",
        "\n",
        "Тут ми створюємо \"мозок\" нашої програми."
      ],
      "metadata": {
        "id": "E0WWbLXWhtwV"
      },
      "id": "E0WWbLXWhtwV"
    },
    {
      "cell_type": "code",
      "source": [
        "# Встановлюємо бібліотеку PySpark\n",
        "!pip install pyspark -q\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Створюємо SparkSession – це наш \"Капітанський місток\"\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"FirstLectureRDD\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Дістаємо SparkContext (sc) – це доступ до \"Машинного відділення\" (RDD API)\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "xH3TSF6egRvQ"
      },
      "id": "xH3TSF6egRvQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`SparkSession` – це сучасна точка входу. Для роботи з RDD дістаємо `sparkContext` (sc), бо саме він відповідає за низькорівневу роботу з розподіленими наборами даних."
      ],
      "metadata": {
        "id": "BKiFinx9iSl-"
      },
      "id": "BKiFinx9iSl-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Створення даних та Трансформації (Lazy Evaluation)\n",
        "\n",
        "Створюємо план обчислень, але Spark ще не починає роботу.\n"
      ],
      "metadata": {
        "id": "CKa8IPhXipee"
      },
      "id": "CKa8IPhXipee"
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Створюємо RDD зі списку (Дані розрізаються на партиції і йдуть до Executors)\n",
        "data = [\"Spark is fast\", \"Spark is fun\", \"Spark is distributed\", \"Big Data is cool\"]\n",
        "rdd = sc.parallelize(data)\n",
        "\n",
        "# 2. Трансформація: Фільтруємо рядки, де є слово \"Spark\"\n",
        "# Spark лише записує це в план (DAG), нічого не обчислюючи!\n",
        "filtered_rdd = rdd.filter(lambda line: \"Spark\" in line)\n",
        "\n",
        "# 3. Трансформація: Перетворюємо рядок на верхній регістр\n",
        "upper_rdd = filtered_rdd.map(lambda line: line.upper())"
      ],
      "metadata": {
        "id": "Fp_i9S0bi26m"
      },
      "id": "Fp_i9S0bi26m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Дія (Action) та Lineage\n",
        "\n",
        "Момент, коли \"план\" перетворюється на \"результат\"."
      ],
      "metadata": {
        "id": "Zv5rIFq1i8GX"
      },
      "id": "Zv5rIFq1i8GX"
    },
    {
      "cell_type": "code",
      "source": [
        "# Викликаємо Action (collect) – тільки зараз Driver дає команду Executor-ам працювати\n",
        "print(\"Результат обробки:\")\n",
        "print(upper_rdd.collect())\n",
        "\n",
        "# Дивимось на \"Родовід\" (Lineage) нашого результату\n",
        "print(\"\\nГраф походження даних (Lineage):\")\n",
        "print(upper_rdd.toDebugString().decode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYe_Rf_NjANr",
        "outputId": "63f1ecfc-df5c-43e1-d03a-4bb01ec09067"
      },
      "id": "lYe_Rf_NjANr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат обробки:\n",
            "['SPARK IS FAST', 'SPARK IS FUN', 'SPARK IS DISTRIBUTED']\n",
            "\n",
            "Граф походження даних (Lineage):\n",
            "(2) PythonRDD[1] at collect at /tmp/ipython-input-952536711.py:3 []\n",
            " |  ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:297 []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lazy Evaluation:** Поки ми не викликали `.collect()`, Spark не витратив жодного мегабайта оперативної пам'яті на обробку.\n",
        "\n",
        "**Lineage:** Команда `toDebugString()` показує ланцюжок: `ParallelCollectionRDD -> PythonRDD`. Це і є той самий \"рецепт\", за яким Spark відновить дані, якщо один із вузлів кластера \"помре\"."
      ],
      "metadata": {
        "id": "-LsAWJRJjHF0"
      },
      "id": "-LsAWJRJjHF0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Як читати Граф походження (Lineage)**\n",
        "\n",
        "Коли ви бачите такий вивід у консолі, читайте його знизу вгору – від першоджерела до фінального результату:\n",
        "\n",
        "**1. Точка входу:** `ParallelCollectionRDD` (Нижній рядок)\n",
        "\n",
        "Це початок шляху ваших даних.\n",
        "\n",
        "- Дані були взяті з пам'яті через `sc.parallelize`.\n",
        "\n",
        "- **ID в дужках** `[ ]`**:** Це просто технічний індекс об'єкта в поточній сесії. Він змінюється щоразу, коли ви створюєте новий набір даних, тому на нього не варто спиратися як на постійну величину.\n",
        "\n",
        "**2. Етап трансформацій:** `PythonRDD` (Верхній рядок)\n",
        "\n",
        "Це результат усіх операцій, які ви застосували до даних (`filter`, `map`).\n",
        "\n",
        "- **Pipelining (Об'єднання):** Spark – розумний оптимізатор. Якщо у вас було декілька послідовних фільтрів та перетворень, він об'єднує їх в один крок обробки (`PythonRDD`), щоб виконати все за один прохід по пам'яті.\n",
        "\n",
        "- **Кількість партицій** `(2)`**:** Число на початку рядка вказує, на скільки частин розбиті дані. У цьому випадку – на 2 частини, які обробляються паралельно на двох ядрах процесора.\n",
        "\n",
        "**3. Тригер виконання:** `at collect`\n",
        "\n",
        "Spark працює за принципом **лінивих обчислень**. Це означає, що він не виконує жодних дій, поки ви не попросите конкретний результат.\n",
        "\n",
        "- `at collect`: Це назва **Action** (дії), яка змусила Spark нарешті \"прокинутися\" і прогнати дані по всьому ланцюжку.\n",
        "\n",
        "- **Шлях до файлу** `/tmp/...`**:** Це точне місце у вашому коді, де було викликано цю дію."
      ],
      "metadata": {
        "id": "mx3ApLmp5apY"
      },
      "id": "mx3ApLmp5apY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Чому цей граф виглядає саме так?**\n",
        "\n",
        "- **Відсутність Shuffle (Перемішування):** Зверніть увагу, що всі рядки стоять один під одним з однаковим відступом (вертикальна риска `|`). Це означає, що дані не пересилалися між вузлами мережі. Все відбулося в межах одного **Stage**.\n",
        "\n",
        "- **Механізм відмовостійкості (Fault Tolerance):** У разі втрати партиції даних під час обчислень, Spark задіює механізм детермінованого повторного обчислення. Оскільки RDD є незмінними (immutable), система звертається до графа походження (Lineage), ідентифікує батьківський вузол (`ParallelCollectionRDD`) і повторно виконує лише ті трансформації, що необхідні для відновлення втраченого фрагмента. Це дозволяє уникнути перезапуску всього завдання та забезпечує цілісність результатів."
      ],
      "metadata": {
        "id": "i_yzeANO-Rp_"
      },
      "id": "i_yzeANO-Rp_"
    },
    {
      "cell_type": "markdown",
      "id": "e4359369",
      "metadata": {
        "id": "e4359369"
      },
      "source": [
        "### 10. Корисні ресурси\n",
        "\n",
        "1. [Що таке Big Data Engineering і як розвиватися у цій сфері](https://dou.ua/lenta/articles/what-is-big-data-engineering/)\n",
        "\n",
        "2. [IBM – What is Big Data?](https://www.ibm.com/think/topics/big-data)\n",
        "\n",
        "3. [How do companies use big data](https://softwaremill.com/how-do-companies-use-big-data/)\n",
        "\n",
        "4. [Офіційний сайт Apache Hadoop](https://hadoop.apache.org/)\n",
        "\n",
        "5. [Спеціалізація Big Data на платформі Coursera](https://www.coursera.org/specializations/big-data)\n",
        "\n",
        "6. [Офіційний сайт Apache Spark](https://spark.apache.org/)\n",
        "\n",
        "7. [Офіційна документація Apache Spark: Cluster Mode Overview – база про Driver, Executor та Cluster Manager](https://spark.apache.org/docs/latest/cluster-overview.html)\n",
        "\n",
        "8. [Курс \"Introduction to Apache Spark\" від Databricks Academy](https://www.databricks.com/training/catalog/introduction-to-apache-spark-3898)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}